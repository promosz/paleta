#!/usr/bin/env python3
"""
Performance Test Runner
Runs comprehensive performance tests for AI services
"""

import sys
import time
import json
from pathlib import Path
import subprocess

def run_performance_tests():
    """Run all performance tests and generate report"""
    print("üöÄ Starting AI Services Performance Tests")
    print("=" * 50)
    
    start_time = time.time()
    
    try:
        # Run pytest with performance tests
        result = subprocess.run([
            sys.executable, "-m", "pytest", 
            "tests/test_performance.py", 
            "-v", "--tb=short"
        ], capture_output=True, text=True, cwd=Path(__file__).parent)
        
        test_time = time.time() - start_time
        
        print("üìä Test Results:")
        print(result.stdout)
        
        if result.stderr:
            print("‚ö†Ô∏è  Warnings/Errors:")
            print(result.stderr)
        
        # Generate performance report
        generate_performance_report(test_time, result.returncode == 0)
        
        return result.returncode == 0
        
    except Exception as e:
        print(f"‚ùå Error running tests: {e}")
        return False

def generate_performance_report(test_time: float, success: bool):
    """Generate performance test report"""
    print("\nüìà Performance Test Report")
    print("=" * 50)
    
    report = {
        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
        "test_duration_seconds": round(test_time, 2),
        "overall_status": "PASSED" if success else "FAILED",
        "targets": {
            "brand_recognition_accuracy": "‚â•80%",
            "category_classification_accuracy": "‚â•75%",
            "profitability_analysis_accuracy": "‚â•75%",
            "model_extraction_accuracy": "‚â•70%",
            "response_time_products": "<2 seconds",
            "response_time_palettes": "<5 seconds",
            "cache_speedup": "‚â•5x for products, ‚â•2x for palettes"
        },
        "improvements": [
            "‚úÖ Enhanced brand recognition with regex patterns",
            "‚úÖ Improved model extraction with specific patterns",
            "‚úÖ Added misspelling and variation handling",
            "‚úÖ Implemented caching for performance",
            "‚úÖ Extended test coverage with 40+ products",
            "‚úÖ Added performance monitoring endpoints"
        ]
    }
    
    print(f"‚è±Ô∏è  Test Duration: {report['test_duration_seconds']}s")
    print(f"üìä Overall Status: {report['overall_status']}")
    
    print("\nüéØ Performance Targets:")
    for target, requirement in report['targets'].items():
        print(f"   ‚Ä¢ {target}: {requirement}")
    
    print("\nüöÄ Improvements Implemented:")
    for improvement in report['improvements']:
        print(f"   {improvement}")
    
    # Save report to file
    report_file = Path(__file__).parent / "performance_report.json"
    with open(report_file, "w") as f:
        json.dump(report, f, indent=2)
    
    print(f"\nüíæ Report saved to: {report_file}")
    
    if success:
        print("\nüéâ All performance tests PASSED!")
        print("‚úÖ AI Services are ready for production use")
    else:
        print("\n‚ùå Some performance tests FAILED!")
        print("‚ö†Ô∏è  Please review the test output above")

def main():
    """Main function"""
    success = run_performance_tests()
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()




















