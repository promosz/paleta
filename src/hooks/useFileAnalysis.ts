import { useCallback, useState } from 'react'
import { useNavigate, useLocation } from 'react-router-dom'
import { useUploadStore, validateFile } from '../stores/uploadStore'
import { useAnalysisStore } from '../stores/analysisStoreSupabase'
import { useCurrentUser } from './useCurrentUser'
import { parserService } from '../utils/parserService'
import { supabaseProductsService } from '../services/supabaseProductsService'
import { CategoryMapperService } from '../services/categoryMapperService'
import { supabase } from '../lib/supabase'

/**
 * Hook do obsÅ‚ugi uploadu i analizy plikÃ³w
 * Zapewnia spÃ³jnÄ… funkcjonalnoÅ›Ä‡ w caÅ‚ej aplikacji
 */
export const useFileAnalysis = () => {
  const navigate = useNavigate()
  const location = useLocation()
  const { supabaseUserId, isLoaded, isSignedIn } = useCurrentUser()
  
  const { 
    getAllParsedProducts, 
    getAllEvaluations, 
    evaluateProducts, 
    isEvaluating,
    addFiles,
    setParsing,
    setParseResult,
    setUploading
  } = useUploadStore()
  
  const { createAnalysis } = useAnalysisStore()
  
  const [isProcessing, setIsProcessing] = useState(false)
  const [error, setError] = useState<string | null>(null)

  /**
   * GÅ‚Ã³wna funkcja przetwarzania plikÃ³w
   */
  const processFiles = useCallback(async (files: File[]) => {
    if (!supabaseUserId) {
      setError('Brak userId - uÅ¼ytkownik nie jest zalogowany')
      console.error('âŒ Brak userId - uÅ¼ytkownik nie jest zalogowany')
      return null
    }

    setIsProcessing(true)
    setError(null)
    setUploading(true)
    setParsing(true)

    try {
      const processedFiles: { file: File; result: any; fileId: string }[] = []

      // Symulacja uploadu i parsowania dla kaÅ¼dego pliku
      for (const file of files) {
        // Symulacja postÄ™pu uploadu
        await new Promise(resolve => {
          let currentProgress = 0
          const progressInterval = setInterval(() => {
            currentProgress += Math.random() * 15 + 5
            currentProgress = Math.min(currentProgress, 100)
            
            if (currentProgress >= 100) {
              clearInterval(progressInterval)
              resolve(undefined)
            }
          }, 200)
        })

        // Parsowanie pliku
        const result = await parserService.parseFile(
          file,
          (progress, status) => {
            console.log(`Parsowanie ${file.name}: ${progress}% - ${status}`)
          }
        )

        // Zapisanie wyniku parsowania
        const fileId = `${Date.now()}-${Math.random().toString(36).substr(2, 9)}`
        setParseResult(fileId, result)
        
        processedFiles.push({ file, result, fileId })
      }

      // Automatyczna ocena produktÃ³w po parsowaniu
      const currentParsedProducts = getAllParsedProducts()
      if (currentParsedProducts.length === 0) {
        throw new Error('Nie znaleziono produktÃ³w do analizy')
      }

      console.log('ðŸŽ¯ Rozpoczynam ocenÄ™ produktÃ³w...')
      await evaluateProducts()
      
      // UtwÃ³rz analizÄ™ z produktami - uÅ¼yj nazwy pierwszego pliku
      const analysisName = files.length === 1 
        ? files[0].name.replace(/\.[^/.]+$/, "") // UsuÅ„ rozszerzenie
        : `${files[0].name.replace(/\.[^/.]+$/, "")} i ${files.length - 1} innych`
      
      // Konwersja przetworzonych plikÃ³w na AnalysisFile
      const analysisFiles = processedFiles.map(({ file, result, fileId }) => ({
        id: fileId,
        name: file.name,
        size: file.size,
        type: file.type,
        uploadedAt: new Date(),
        status: 'completed' as const,
        productCount: result.products.length
      }))
      
      console.log('ðŸš€ Tworzenie analizy z plikami:', analysisFiles.length)
      console.log('ðŸ“ Pliki:', analysisFiles.map(f => ({ name: f.name, size: f.size })))
      
      // Tworzenie analizy
      const analysis = await createAnalysis(
        analysisName,
        `Analiza utworzona automatycznie z ${files.map(f => f.name).join(', ')}`,
        'file_upload',
        supabaseUserId,
        analysisFiles
      )
      
      console.log('âœ… Analiza utworzona:', analysis.id)
      
      // **NORMALIZACJA KATEGORII PRZED ZAPISEM** - kluczowe!
      console.log('ðŸ”„ NormalizujÄ™ kategorie przed zapisem...')
      
      // Importuj CategoryNormalizer
      const { CategoryNormalizer } = await import('../utils/categoryNormalizer')
      
      // Zbierz wszystkie unikalne kategorie z produktÃ³w
      const uniqueCategories = Array.from(
        new Set(currentParsedProducts.map(p => p.category).filter(Boolean))
      )
      
      console.log('ðŸ“Š Znaleziono unikalne kategorie:', uniqueCategories)
      
      // Pobierz juÅ¼ istniejÄ…ce kategorie z bazy (z WSZYSTKICH analiz uÅ¼ytkownika)
      const { data: existingProducts } = await (supabase as any)
        .from('products')
        .select('category')
        .eq('user_id', supabaseUserId)
        .not('category', 'is', null)
      
      const existingCategories: string[] = Array.from(
        new Set((existingProducts || []).map((p: any) => p.category as string).filter(Boolean))
      )
      
      console.log('ðŸ“‹ IstniejÄ…ce kategorie w bazie:', existingCategories)
      
      // Mapuj kaÅ¼dÄ… kategoriÄ™
      const categoryMapping = new Map<string, string>()
      
      for (const originalCategory of uniqueCategories) {
        if (!originalCategory) continue
        
        // Normalizuj kategoriÄ™
        const normalized = CategoryNormalizer.normalize(originalCategory)
        
        // SprawdÅº czy znormalizowana kategoria juÅ¼ istnieje
        const existingMatch = existingCategories.find(
          (cat: string) => cat.toUpperCase() === normalized.toUpperCase()
        )
        
        if (existingMatch) {
          // UÅ¼yj istniejÄ…cej kategorii (zachowaj dokÅ‚adnÄ… formÄ™ z bazy)
          categoryMapping.set(originalCategory, existingMatch as string)
          console.log(`âœ“ Mapowanie: "${originalCategory}" â†’ "${existingMatch}" (istniejÄ…ca)`)
        } else {
          // Dodaj nowÄ… znormalizowanÄ… kategoriÄ™
          categoryMapping.set(originalCategory, normalized)
          existingCategories.push(normalized) // Dodaj do listy dla kolejnych iteracji
          console.log(`ðŸ†• Mapowanie: "${originalCategory}" â†’ "${normalized}" (nowa)`)
        }
      }
      
      // Zastosuj mapowanie do produktÃ³w PRZED zapisem
      const productsWithMappedCategories = currentParsedProducts.map(product => ({
        ...product,
        category: product.category ? (categoryMapping.get(product.category) || product.category) : 'INNE'
      }))
      
      console.log('âœ… Kategorie znormalizowane, zapisujÄ™ produkty...')
      
      // Zapisz produkty do bazy danych (z juÅ¼ znormalizowanymi kategoriami)
      const currentEvaluations = getAllEvaluations()
      
      try {
        const savedProducts = await supabaseProductsService.addProducts(
          productsWithMappedCategories,
          analysis.id,
          supabaseUserId,
          currentEvaluations
        )
        
        console.log('âœ… Produkty zapisane w bazie:', savedProducts.length)
        
        // Zapisz mapowania do tabeli category_mappings dla przyszÅ‚ych referencji
        try {
          for (const [original, normalized] of categoryMapping) {
            await CategoryMapperService.upsertMapping(
              supabaseUserId,
              original,
              normalized,
              false, // automatyczne
              analysis.id
            )
          }
          console.log('âœ… Mapowania zapisane w bazie')
        } catch (mapError) {
          console.error('âš ï¸ BÅ‚Ä…d zapisu mapowaÅ„ (kontynuujÄ™):', mapError)
        }
        
        // Aktualizuj statystyki analizy
        const stats = await supabaseProductsService.getProductStats(analysis.id, supabaseUserId)
        console.log('ðŸ“ˆ Statystyki:', stats)
        
      } catch (error) {
        console.error('âŒ BÅ‚Ä…d zapisu produktÃ³w:', error)
        // Nie przerywamy - analiza jest utworzona, produkty moÅ¼na dodaÄ‡ pÃ³Åºniej
      }

      return {
        analysis,
        processedFiles: processedFiles.map(pf => ({
          name: pf.file.name,
          size: pf.file.size,
          type: pf.file.type,
          productsCount: pf.result.products.length,
          fileId: pf.fileId
        }))
      }
    } catch (error) {
      console.error('BÅ‚Ä…d przetwarzania plikÃ³w:', error)
      setError(error instanceof Error ? error.message : 'BÅ‚Ä…d przetwarzania plikÃ³w')
      return null
    } finally {
      setIsProcessing(false)
      setUploading(false)
      setParsing(false)
    }
  }, [supabaseUserId, getAllParsedProducts, getAllEvaluations, evaluateProducts, addFiles, setParsing, setParseResult, setUploading, createAnalysis])

  /**
   * Funkcja obsÅ‚ugujÄ…ca drop/upload plikÃ³w
   */
  const handleFileDrop = useCallback(async (acceptedFiles: File[], options?: {
    navigateToDashboard?: boolean
    onSuccess?: (analysisId: string) => void
  }) => {
    if (acceptedFiles.length === 0) return

    // Walidacja plikÃ³w
    const validFiles: File[] = []
    const errors: string[] = []

    acceptedFiles.forEach(file => {
      const validation = validateFile(file)
      if (validation.isValid) {
        validFiles.push(file)
      } else {
        errors.push(`${file.name}: ${validation.error}`)
      }
    })

    if (errors.length > 0) {
      console.warn('BÅ‚Ä™dy walidacji plikÃ³w:', errors)
      setError(errors.join('\n'))
    }

    if (validFiles.length === 0) return

    // Dodaj pliki do store
    addFiles(validFiles)
    
    // Rozpocznij przetwarzanie
    const result = await processFiles(validFiles)
    
    if (result) {
      // WywoÅ‚aj callback sukcesu jeÅ›li jest podany
      if (options?.onSuccess) {
        options.onSuccess(result.analysis.id)
      }
      
      // Nawiguj do Dashboard jeÅ›li jest wymagane
      if (options?.navigateToDashboard) {
        const dashboardPath = location.pathname.startsWith('/paleta') ? '/paleta/dashboard' : '/dashboard'
        navigate(dashboardPath, { 
          state: { 
            selectedAnalysisId: result.analysis.id,
            processedFiles: result.processedFiles
          }
        })
      }
    }
  }, [addFiles, processFiles, navigate, location])

  return {
    handleFileDrop,
    processFiles,
    isProcessing,
    isEvaluating,
    error,
    isLoaded,
    isSignedIn,
    supabaseUserId
  }
}

